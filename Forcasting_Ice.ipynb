{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba45d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0810044f",
   "metadata": {},
   "source": [
    "# READ-ME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fb46ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEPENDENCIES: pandas, numpy, tqdm, matplotlib, rasterio, multiprocessing\n",
    "\n",
    "INPUT DATA ---> ICE CONCENTRATION DATA FROM THE NATIONAL SNOW AND ICE DATA CENTER (NSIDC)\n",
    "- DOWNLOAD THE DATA FROM: https://noaadata.apps.nsidc.org/NOAA/G02135/north/daily/geotiff/\n",
    "\n",
    "DUE TO THE SIZE OF THE PROJECT, BACK-UP DATA FILES WERE CREATED, ONE HAS BEEN PROVIDED FOR 'future_ice_data' IN CASE OF ANY ISSUES WITH THE ORIGINAL DATA FILES.\n",
    "\n",
    "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "WHAT THIS NOTEBOOK DOES:\n",
    "- MODELS FUTURE ARCTIC ICE CONCETRATION USING A LINEAR DECAY MODEL BASED ON HISTORIAL SEASONALITY DATA \n",
    "- APPLIES THE FORCASTED ICE CONCENTRATION TO TIF FILES TO CREATE FUTURE ICE CONCENTRATION MAPS\n",
    "\n",
    "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "FOR QUESTION OR ISSUES CONTACT: \n",
    "- Ioannis Thomopoulos       -->  ioannis.thomopoulos@studbocconi.it\n",
    "- Jacopo D'Angelo           -->  jacopo.dangelo@studbocconi.it\n",
    "- Max Rienth                -->  maximilian.rienth@studbocconi.it\n",
    "- Luca Milani               -->  luca.milani2@studbocconi.it\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23793f4e",
   "metadata": {},
   "source": [
    "# DATA COLLECTION + CONFIGURATION + GENERAL SET-UP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e71bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'original_data/ice_tifs_historic'\n",
    "outfile = 'created_data/predicted_concentration.csv'\n",
    "nodata_list_file = 'created_data/nodata_pixels.csv'\n",
    "temp_dir = 'created_data/IGNORE_THIS___pickling_file'\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "pattern = re.compile(r'(\\d{4})_N_(\\d{8})_concentration_v3\\.0\\.tif')\n",
    "train_files = []\n",
    "for fname in os.listdir(data_dir):\n",
    "    m = pattern.match(fname)\n",
    "    if not m:\n",
    "        continue\n",
    "    year = int(m.group(1))\n",
    "    date = datetime.strptime(m.group(2), '%Y%m%d')\n",
    "    if 2015 <= year <= 2020 and not (date.month == 2 and date.day == 29):\n",
    "        train_files.append((date, os.path.join(data_dir, fname)))\n",
    "train_files.sort(key=lambda x: x[0])\n",
    "\n",
    "with rasterio.open(train_files[0][1]) as src0:\n",
    "    height, width = src0.height, src0.width\n",
    "    nodata_val = src0.nodata\n",
    "\n",
    "stack = np.empty((len(train_files), height, width), dtype=np.float32)\n",
    "mask_nodata = np.zeros((len(train_files), height, width), dtype=bool)\n",
    "for i, (_, path) in enumerate(tqdm(train_files, desc='Loading training rasters')):\n",
    "    with rasterio.open(path) as src:\n",
    "        arr = src.read(1).astype(np.float32)\n",
    "    nodata_mask = (arr == nodata_val)\n",
    "    stack[i] = np.where(nodata_mask, np.nan, arr)\n",
    "    mask_nodata[i] = nodata_mask\n",
    "\n",
    "nodata_pixels  = np.any(mask_nodata, axis=0)\n",
    "water_pixels   = np.nanmax(stack, axis=0) <= 10\n",
    "land_pixels    = np.nanmax(stack, axis=0) > 2000\n",
    "variable_mask  = ~(nodata_pixels | water_pixels | land_pixels)\n",
    "rows, cols     = np.where(variable_mask)\n",
    "\n",
    "mdays = [31,28,31,30,31,30,31,31,30,31,30,31]\n",
    "baseline = np.zeros((365, height, width), dtype=np.float64)\n",
    "counts   = np.zeros(365, dtype=int)\n",
    "\n",
    "for date, _ in train_files:\n",
    "    doy = sum(mdays[:date.month-1]) + date.day - 1\n",
    "    idx = next(i for i, (d, _) in enumerate(train_files) if d == date)\n",
    "    baseline[doy] += np.nan_to_num(stack[idx], nan=0.0)\n",
    "    counts[doy]   += 1\n",
    "\n",
    "for doy in range(365):\n",
    "    if counts[doy] > 0:\n",
    "        baseline[doy] /= counts[doy]\n",
    "    else:\n",
    "        baseline[doy].fill(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a626722a",
   "metadata": {},
   "source": [
    "# MODELLING ICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4262a207",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0         = datetime(2024, 9, 15)\n",
    "t_end      = datetime(2050, 9, 15)\n",
    "total_days = (t_end - t0).days\n",
    "\n",
    "start_date = datetime(2025, 1, 1)\n",
    "end_date   = datetime(2050, 12, 31)\n",
    "dates = []\n",
    "current = start_date\n",
    "while current <= end_date:\n",
    "    # skip Feb 29\n",
    "    if not (current.month == 2 and current.day == 29):\n",
    "        dates.append(current)\n",
    "    current += timedelta(days=1)\n",
    "\n",
    "def init_worker(baseline_arr, rows_arr, cols_arr):\n",
    "    global BASELINE, ROWS, COLS\n",
    "    BASELINE = baseline_arr\n",
    "    ROWS     = rows_arr\n",
    "    COLS     = cols_arr\n",
    "\n",
    "def process_date(cur_date):\n",
    "    # multiplier\n",
    "    if cur_date < t0:\n",
    "        M = 1.0\n",
    "    elif cur_date > t_end:\n",
    "        M = 0.0\n",
    "    else:\n",
    "        M = 1.0 - ((cur_date - t0).days / total_days)\n",
    "\n",
    "    # day-of-year index\n",
    "    doy = sum(mdays[:cur_date.month-1]) + cur_date.day - 1\n",
    "    base = BASELINE[doy]           # (H, W)\n",
    "    pred = base * M                # (H, W)\n",
    "\n",
    "    # write temp CSV\n",
    "    fname = os.path.join(temp_dir, f\"{cur_date.strftime('%Y%m%d')}.csv\")\n",
    "    with open(fname, 'w') as f:\n",
    "        for r, c in zip(ROWS, COLS):\n",
    "            f.write(f\"{cur_date.strftime('%Y-%m-%d')},{r},{c},{pred[r, c]:.3f}\\n\")\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d3b8a4",
   "metadata": {},
   "source": [
    "NOTE: The cell below will take a while to run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeecf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    ctx = mp.get_context('fork')   # force fork, avoids pickling init_worker\n",
    "    with ctx.Pool(\n",
    "            processes=8,                       # cap at 8 workers\n",
    "            initializer=init_worker,           # each worker gets baseline & mask\n",
    "            initargs=(baseline, rows, cols)\n",
    "        ) as pool:\n",
    "        for _ in tqdm(\n",
    "                pool.imap_unordered(process_date, dates),\n",
    "                total=len(dates),\n",
    "                desc='Predicting dates'\n",
    "            ):\n",
    "            pass\n",
    "\n",
    "    # === 10) Merge temp CSVs ===\n",
    "    temp_files = sorted(os.listdir(temp_dir))\n",
    "    with open(outfile, 'w') as fout:\n",
    "        fout.write('date,row,col,predicted_concentration\\n')\n",
    "        for fname in tqdm(temp_files, desc='Merging CSVs'):\n",
    "            path = os.path.join(temp_dir, fname)\n",
    "            with open(path) as fin:\n",
    "                fout.write(fin.read())\n",
    "            os.remove(path)\n",
    "\n",
    "    # === 11) Save nodata pixel list ===\n",
    "    nodata_coords = list(zip(*np.where(nodata_pixels)))\n",
    "    with open(nodata_list_file, 'w') as fn:\n",
    "        fn.write('row,col\\n')\n",
    "        for r, c in tqdm(nodata_coords, desc='Saving nodata pixels'):\n",
    "            fn.write(f'{r},{c}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6950acf",
   "metadata": {},
   "source": [
    "# APPLYING FORCASTED ICE TO ARCTIC MAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c908bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_ice_data = pd.read_csv('created_data/predicted_concentration.csv')\n",
    "# future_ice_data = pd.read_csv('created_data/backup_data/predicted_concentration_backup.csv')  # Uncomment to use backup file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee1bac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir      = 'created_data/predicted_tifs'\n",
    "template_path = 'original_data/ice_tifs_historic/2024_N_20241231_concentration_v3.0.tif'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "with rasterio.open(template_path) as src:\n",
    "    meta     = src.meta.copy()\n",
    "    template = src.read(1)\n",
    "    nodata   = src.nodata\n",
    "    height, width = src.height, src.width\n",
    "\n",
    "# derive masks\n",
    "land_mask   = template > 2000\n",
    "water_mask  = template == 0\n",
    "\n",
    "# build palette\n",
    "cmap = {}\n",
    "for i in range(0, 255):\n",
    "    ratio = i / 254.0\n",
    "    r = int(ratio * 255)\n",
    "    g = int(ratio * 255)\n",
    "    b = 255\n",
    "    cmap[i] = (r, g, b)\n",
    "cmap[200] = (0, 255, 0)     # land → green\n",
    "cmap[255] = (128, 0, 128)   # nodata → purple\n",
    "\n",
    "meta.update({\n",
    "    'dtype':       'uint8',\n",
    "    'count':       1,\n",
    "    'photometric': 'palette',\n",
    "    'nodata':      255\n",
    "})\n",
    "\n",
    "\n",
    "grouped = future_ice_data.groupby('date')\n",
    "\n",
    "for date_token, df_day in grouped:\n",
    "    # format date_token to YYYYMMDD string\n",
    "    date_str = pd.to_datetime(date_token).strftime('%Y%m%d')\n",
    "    out_tif  = os.path.join(out_dir, f'{date_str}_predicted.tif')\n",
    "\n",
    "    # start with all pixels nodata\n",
    "    pal_arr = np.full((height, width), 255, dtype=np.uint8)\n",
    "\n",
    "    # extract numpy arrays for this date\n",
    "    rows = df_day['row'].to_numpy(dtype=int)\n",
    "    cols = df_day['col'].to_numpy(dtype=int)\n",
    "    vals = df_day['predicted_concentration'].to_numpy(dtype=float)\n",
    "\n",
    "    # map concentration → 0–254\n",
    "    idxs = np.rint(vals / 1000.0 * 254).astype(np.int16)\n",
    "    idxs = np.clip(idxs, 0, 254)\n",
    "\n",
    "    # fill variable pixels\n",
    "    pal_arr[rows, cols] = idxs\n",
    "\n",
    "    # overwrite water and land\n",
    "    pal_arr[water_mask] = 0\n",
    "    pal_arr[land_mask]  = 200\n",
    "\n",
    "    # write out\n",
    "    with rasterio.open(out_tif, 'w', **meta) as dst:\n",
    "        dst.write(pal_arr, 1)\n",
    "        dst.write_colormap(1, cmap)\n",
    "\n",
    "    print(f'Wrote {out_tif}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "General_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
